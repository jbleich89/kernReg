% Generated by roxygen2 (4.0.1): do not edit by hand
\name{kpcr}
\alias{kpcr}
\title{Run a linear regression using Kernel PCA}
\usage{
kpcr(kpca_object, y, num_pcs = NULL, frac_var = NULL)
}
\arguments{
\item{kpca_object}{The object that contains the kernel, the kernelized data with its eigendecomposition}

\item{y}{The response to be regressed on the features which are the principal components of the kernelized data}

\item{num_pcs}{The number of principal components to use for the regression (this or \code{frac_var} must be specified)}

\item{frac_var}{Pick the number of principal components to use based on the fraction of variance to explain (this or \code{num_pcs} must be specified)}
}
\value{
An lm object with the kpca_object embedded as well as the number of principal components used
}
\description{
\code{kpcr} runs a linear regression on features created from an eigendecomposition
of a certain dimension of the kernelized data
}
\examples{
\dontrun{
#pull the predictor matrix and response from the Boston Housing Data
data(Boston)
y = Boston$medv
Boston$medv = NULL
X = as.matrix(Boston)
#build a KPCA object using the anova kernel with hyperparameters sigma = 0.1 and d = 3
kpca_obj = build_kpca_object(X, "anova", c(0.1, 3))
#build a KPCR model using 75\% of the variance explained by the kernel matrix
kpcr_mod = kpcr(kpca_obj, y, frac_var = 0.75)
#printing the object will run the default print for the lm object, more useful is summary:
summary(kpcr_mod)
}
}
\author{
Justin Bleich and Adam Kapelner
}
\references{
Berk, R., Bleich, J., Kapelner, A.,  Henderson, J. and Kurtz, E., Using Regression Kernels to Forecast A Failure to Appear in Court. (2014) working paper
}
\seealso{
\code{\link{kpclr}}
}

